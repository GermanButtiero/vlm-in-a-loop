{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to download only a subset of the COCO dataset we need to:\n",
    "\n",
    "1- Download the whole dataset\n",
    "\n",
    "2- Create a dataset that select only some categories and it copies the images into a folder \"data\"\n",
    "\n",
    "3- Move the data folder to your HPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/Users/germa/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/Users/germa/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Download the COCO-2017 validation split and load it into FiftyOne\n",
    "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n",
    "\n",
    "# Give the dataset a new name, and make it persistent\n",
    "dataset.name = \"coco-2017-validation\"\n",
    "dataset.persistent = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/Users/germa/fiftyone/coco-2017/train' if necessary\n",
      "Found annotations at '/Users/germa/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'coco-2017-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset_train = foz.load_zoo_dataset(\"coco-2017\", split=\"train\")\n",
    "dataset_train.name = \"coco-2017-train\"\n",
    "dataset_train.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'test' to '/Users/germa/fiftyone/coco-2017/test' if necessary\n",
      "Found test info at '/Users/germa/fiftyone/coco-2017/raw/image_info_test2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'test' is sufficient\n",
      "Loading existing dataset 'coco-2017-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset_test = foz.load_zoo_dataset(\"coco-2017\", split=\"test\")\n",
    "dataset_test.name = \"coco-2017-test\"\n",
    "dataset_test.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2  # OpenCV needed for polygon drawing\n",
    "from pycocotools import mask as coco_mask\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil\n",
    "\n",
    "config = json.load(open(\"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoSegmentationDatasetMRCNN(Dataset):\n",
    "    def __init__(self, image_dir, seg_annotation_file, categories_to_keep=[1], min_area_threshold=655, output_dir=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.coco_seg = COCO(seg_annotation_file)\n",
    "        self.min_area_threshold = min_area_threshold\n",
    "        self.categories_to_keep = categories_to_keep\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # Filter images to keep only those containing objects from specified categories\n",
    "        self.image_ids = []\n",
    "        for cat_id in self.categories_to_keep:\n",
    "            ann_ids = self.coco_seg.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
    "            anns = self.coco_seg.loadAnns(ann_ids)\n",
    "            valid_anns = [ann for ann in anns if ann['area'] >= self.min_area_threshold]\n",
    "            img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
    "            self.image_ids.extend(img_ids)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        self.image_ids = list(set(self.image_ids))\n",
    "        print(f\"Dataset contains {len(self.image_ids)} images with categories {categories_to_keep}\")\n",
    "        \n",
    "        # For visualization, create a category mapping\n",
    "        self.category_map = {}\n",
    "        for cat_id in self.categories_to_keep:\n",
    "            cat_info = self.coco_seg.loadCats(cat_id)[0]\n",
    "            self.category_map[cat_id] = cat_info['name']\n",
    "        \n",
    "        # Copy images to output directory if specified\n",
    "        if output_dir:\n",
    "            self.copy_images_to_output_dir()\n",
    "\n",
    "    def copy_images_to_output_dir(self):\n",
    "        \"\"\"Copy filtered images to the output directory\"\"\"\n",
    "        if not self.output_dir:\n",
    "            return\n",
    "            \n",
    "        # Create output directory\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Copying {len(self.image_ids)} images to {self.output_dir}...\")\n",
    "        copied_count = 0\n",
    "        \n",
    "        for img_id in self.image_ids:\n",
    "            # Get image info\n",
    "            img_info = self.coco_seg.loadImgs(img_id)[0]\n",
    "            \n",
    "            # Source and destination paths\n",
    "            src_path = os.path.join(self.image_dir, img_info[\"file_name\"])\n",
    "            dst_path = os.path.join(self.output_dir, img_info[\"file_name\"])\n",
    "            \n",
    "            # Copy image if source exists\n",
    "            if os.path.exists(src_path):\n",
    "                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                copied_count += 1\n",
    "            else:\n",
    "                print(f\"Warning: Could not find {src_path}\")\n",
    "        \n",
    "        print(f\"Copied {copied_count} images to {self.output_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_info = self.coco_seg.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = transforms.ToTensor()(image)\n",
    "        \n",
    "        # Load annotations\n",
    "        ann_ids = self.coco_seg.getAnnIds(imgIds=image_id, catIds=self.categories_to_keep, iscrowd=False)\n",
    "        anns = self.coco_seg.loadAnns(ann_ids)\n",
    "        \n",
    "        # Initialize target dictionary\n",
    "        target = {}\n",
    "        boxes = []\n",
    "        masks = []\n",
    "        labels = []\n",
    "        category_ids = []  # Keep original category IDs for reference\n",
    "        \n",
    "        # Process each annotation\n",
    "        for ann in anns:\n",
    "            if ann['area'] < self.min_area_threshold:\n",
    "                continue\n",
    "                \n",
    "            # Get bounding box\n",
    "            bbox = ann['bbox']  # [x, y, width, height] format\n",
    "            # Convert to [x1, y1, x2, y2] format\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "            \n",
    "            # Get mask\n",
    "            mask = self.coco_seg.annToMask(ann)\n",
    "            masks.append(torch.as_tensor(mask, dtype=torch.uint8))\n",
    "            \n",
    "            # Keep original category ID for reference\n",
    "            category_ids.append(ann['category_id'])\n",
    "            \n",
    "            # For segmentation only, use class 1 for all foreground objects\n",
    "            labels.append(1)  # 1 for foreground, 0 for background\n",
    "        \n",
    "        # Convert to tensor format\n",
    "        if boxes:\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.stack(masks)\n",
    "            target[\"category_ids\"] = torch.as_tensor(category_ids, dtype=torch.int64)  # original IDs for reference\n",
    "        else:\n",
    "            # Empty annotations\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.zeros((0, image.shape[1], image.shape[2]), dtype=torch.uint8)\n",
    "            target[\"category_ids\"] = torch.zeros((0), dtype=torch.int64)\n",
    "        \n",
    "        target[\"image_id\"] = torch.tensor([image_id])\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.64s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset contains 10267 images with categories [84, 31, 52]\n",
      "Copying 10267 images to data/train...\n",
      "Copied 10267 images to data/train\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset contains 443 images with categories [84, 31, 52]\n",
      "Copying 443 images to data/validation...\n",
      "Copied 443 images to data/validation\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CocoSegmentationDatasetMRCNN(\n",
    "    config[\"train_image_dir\"],\n",
    "    config[\"train_annotation_file\"],\n",
    "    categories_to_keep=[84,31,52],\n",
    "    min_area_threshold=655,\n",
    "    output_dir=\"data/train\"\n",
    ")\n",
    "\n",
    "dataset_val = CocoSegmentationDatasetMRCNN(\n",
    "    config[\"val_image_dir\"],\n",
    "    config[\"val_annotation_file\"],\n",
    "    categories_to_keep=[84,31,52],\n",
    "    min_area_threshold=655,\n",
    "    output_dir=\"data/validation\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
