{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to download only a subset of the COCO dataset we need to:\n",
    "\n",
    "1- Download the whole dataset\n",
    "\n",
    "2- Create a dataset that select only some categories and it copies the images into a folder \"data\"\n",
    "\n",
    "3- Move the data folder to your HPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/Users/germa/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/Users/germa/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Download the COCO-2017 validation split and load it into FiftyOne\n",
    "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n",
    "\n",
    "# Give the dataset a new name, and make it persistent\n",
    "dataset.name = \"coco-2017-validation\"\n",
    "dataset.persistent = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/Users/germa/fiftyone/coco-2017/train' if necessary\n",
      "Found annotations at '/Users/germa/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'coco-2017-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset_train = foz.load_zoo_dataset(\"coco-2017\", split=\"train\")\n",
    "dataset_train.name = \"coco-2017-train\"\n",
    "dataset_train.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'test' to '/Users/germa/fiftyone/coco-2017/test' if necessary\n",
      "Found test info at '/Users/germa/fiftyone/coco-2017/raw/image_info_test2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'test' is sufficient\n",
      "Loading existing dataset 'coco-2017-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset_test = foz.load_zoo_dataset(\"coco-2017\", split=\"test\")\n",
    "dataset_test.name = \"coco-2017-test\"\n",
    "dataset_test.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2  # OpenCV needed for polygon drawing\n",
    "from pycocotools import mask as coco_mask\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil\n",
    "\n",
    "config = json.load(open(\"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoSegmentationDatasetMRCNN(Dataset):\n",
    "    def __init__(self, image_dir, seg_annotation_file, categories_to_keep=[1], min_area_threshold=655, output_dir=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.coco_seg = COCO(seg_annotation_file)\n",
    "        self.min_area_threshold = min_area_threshold\n",
    "        self.categories_to_keep = categories_to_keep\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # Filter images to keep only those containing objects from specified categories\n",
    "        self.image_ids = []\n",
    "        for cat_id in self.categories_to_keep:\n",
    "            ann_ids = self.coco_seg.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
    "            anns = self.coco_seg.loadAnns(ann_ids)\n",
    "            valid_anns = [ann for ann in anns if ann['area'] >= self.min_area_threshold]\n",
    "            img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
    "            self.image_ids.extend(img_ids)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        self.image_ids = list(set(self.image_ids))\n",
    "        print(f\"Dataset contains {len(self.image_ids)} images with categories {categories_to_keep}\")\n",
    "        \n",
    "        # For visualization, create a category mapping\n",
    "        self.category_map = {}\n",
    "        for cat_id in self.categories_to_keep:\n",
    "            cat_info = self.coco_seg.loadCats(cat_id)[0]\n",
    "            self.category_map[cat_id] = cat_info['name']\n",
    "        \n",
    "        # Copy images to output directory if specified\n",
    "        if output_dir:\n",
    "            self.copy_images_to_output_dir()\n",
    "\n",
    "    def copy_images_to_output_dir(self):\n",
    "        \"\"\"Copy filtered images to the output directory\"\"\"\n",
    "        if not self.output_dir:\n",
    "            return\n",
    "            \n",
    "        # Create output directory\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Copying {len(self.image_ids)} images to {self.output_dir}...\")\n",
    "        copied_count = 0\n",
    "        \n",
    "        for img_id in self.image_ids:\n",
    "            # Get image info\n",
    "            img_info = self.coco_seg.loadImgs(img_id)[0]\n",
    "            \n",
    "            # Source and destination paths\n",
    "            src_path = os.path.join(self.image_dir, img_info[\"file_name\"])\n",
    "            dst_path = os.path.join(self.output_dir, img_info[\"file_name\"])\n",
    "            \n",
    "            # Copy image if source exists\n",
    "            if os.path.exists(src_path):\n",
    "                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                copied_count += 1\n",
    "            else:\n",
    "                print(f\"Warning: Could not find {src_path}\")\n",
    "        \n",
    "        print(f\"Copied {copied_count} images to {self.output_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_info = self.coco_seg.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = transforms.ToTensor()(image)\n",
    "        \n",
    "        # Load annotations\n",
    "        ann_ids = self.coco_seg.getAnnIds(imgIds=image_id, catIds=self.categories_to_keep, iscrowd=False)\n",
    "        anns = self.coco_seg.loadAnns(ann_ids)\n",
    "        \n",
    "        # Initialize target dictionary\n",
    "        target = {}\n",
    "        boxes = []\n",
    "        masks = []\n",
    "        labels = []\n",
    "        category_ids = []  # Keep original category IDs for reference\n",
    "        \n",
    "        # Process each annotation\n",
    "        for ann in anns:\n",
    "            if ann['area'] < self.min_area_threshold:\n",
    "                continue\n",
    "                \n",
    "            # Get bounding box\n",
    "            bbox = ann['bbox']  # [x, y, width, height] format\n",
    "            # Convert to [x1, y1, x2, y2] format\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "            \n",
    "            # Get mask\n",
    "            mask = self.coco_seg.annToMask(ann)\n",
    "            masks.append(torch.as_tensor(mask, dtype=torch.uint8))\n",
    "            \n",
    "            # Keep original category ID for reference\n",
    "            category_ids.append(ann['category_id'])\n",
    "            \n",
    "            # For segmentation only, use class 1 for all foreground objects\n",
    "            labels.append(1)  # 1 for foreground, 0 for background\n",
    "        \n",
    "        # Convert to tensor format\n",
    "        if boxes:\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.stack(masks)\n",
    "            target[\"category_ids\"] = torch.as_tensor(category_ids, dtype=torch.int64)  # original IDs for reference\n",
    "        else:\n",
    "            # Empty annotations\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.zeros((0, image.shape[1], image.shape[2]), dtype=torch.uint8)\n",
    "            target[\"category_ids\"] = torch.zeros((0), dtype=torch.int64)\n",
    "        \n",
    "        target[\"image_id\"] = torch.tensor([image_id])\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/labels/labels_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_train = \u001b[43mCocoSegmentationDatasetMRCNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_image_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_annotation_file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategories_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m84\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m31\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m52\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_area_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m655\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m dataset_val = CocoSegmentationDatasetMRCNN(\n\u001b[32m     10\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mval_image_dir\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     11\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mval_annotation_file\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33mdata/validation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mCocoSegmentationDatasetMRCNN.__init__\u001b[39m\u001b[34m(self, image_dir, seg_annotation_file, categories_to_keep, min_area_threshold, output_dir)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_dir, seg_annotation_file, categories_to_keep=[\u001b[32m1\u001b[39m], min_area_threshold=\u001b[32m655\u001b[39m, output_dir=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mself\u001b[39m.image_dir = image_dir\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28mself\u001b[39m.coco_seg = \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_annotation_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.min_area_threshold = min_area_threshold\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mself\u001b[39m.categories_to_keep = categories_to_keep\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/vlm/lib/python3.13/site-packages/pycocotools/coco.py:81\u001b[39m, in \u001b[36mCOCO.__init__\u001b[39m\u001b[34m(self, annotation_file)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloading annotations into memory...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     80\u001b[39m tic = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     82\u001b[39m     dataset = json.load(f)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)==\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m not supported\u001b[39m\u001b[33m'\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/labels/labels_train.json'"
     ]
    }
   ],
   "source": [
    "dataset_train = CocoSegmentationDatasetMRCNN(\n",
    "    config[\"train_image_dir\"],\n",
    "    config[\"train_annotation_file\"],\n",
    "    categories_to_keep=[84,31,52],\n",
    "    min_area_threshold=655,\n",
    "    output_dir=\"data/train\"\n",
    ")\n",
    "\n",
    "dataset_val = CocoSegmentationDatasetMRCNN(\n",
    "    config[\"val_image_dir\"],\n",
    "    config[\"val_annotation_file\"],\n",
    "    categories_to_keep=[84,31,52],\n",
    "    min_area_threshold=655,\n",
    "    output_dir=\"data/validation\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
