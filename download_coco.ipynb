{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "4602a148",
                "language": "markdown"
            },
            "source": [
                "In order to download only a subset of the COCO dataset we need to:\n",
                "\n",
                "1- Download and extract the annotation files\n",
                "\n",
                "2- Filter the annotations to identify images containing our target categories\n",
                "\n",
                "3- Download only a limited number of images per category to the \"data\" folder\n",
                "\n",
                "4- Move the data folder to your HPC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "11d2d2de",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "import requests\n",
                "import fiftyone as fo\n",
                "from pycocotools.coco import COCO\n",
                "from tqdm import tqdm\n",
                "\n",
                "# URLs for COCO annotation files\n",
                "ANNOTATION_URLS = {\n",
                "    'train': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
                "    'val': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
                "    'test': 'http://images.cocodataset.org/annotations/image_info_test2017.zip'\n",
                "}\n",
                "\n",
                "# URLs for image files\n",
                "IMAGE_URLS = {\n",
                "    'train': 'http://images.cocodataset.org/zips/train2017.zip',\n",
                "    'val': 'http://images.cocodataset.org/zips/val2017.zip',\n",
                "    'test': 'http://images.cocodataset.org/zips/test2017.zip'\n",
                "}\n",
                "\n",
                "# Categories we want to download (category IDs 84, 31, 52)\n",
                "CATEGORIES_TO_KEEP = [84, 16, 13, 24]\n",
                "#[book, bird, stop sign, zebra] -->look up in classes.txt\n",
                "# Maximum images per category (set to None for unlimited)\n",
                "MAX_IMAGES_PER_CATEGORY = 700  # Change this number as needed\n",
                "\n",
                "def download_file(url, target_path):\n",
                "    \"\"\"Download a file if it doesn't exist\"\"\"\n",
                "    if os.path.exists(target_path):\n",
                "        print(f\"File already exists: {target_path}\")\n",
                "        return\n",
                "    \n",
                "    print(f\"Downloading {url} to {target_path}\")\n",
                "    with requests.get(url, stream=True) as r:\n",
                "        r.raise_for_status()\n",
                "        with open(target_path, 'wb') as f:\n",
                "            for chunk in r.iter_content(chunk_size=8192):\n",
                "                f.write(chunk)\n",
                "\n",
                "def download_and_extract_annotations(split):\n",
                "    \"\"\"Download and extract annotation files for a specific split\"\"\"\n",
                "    import zipfile\n",
                "    \n",
                "    # Create directories\n",
                "    os.makedirs('annotations', exist_ok=True)\n",
                "    \n",
                "    # Download annotations\n",
                "    zip_path = f'annotations_{split}2017.zip'\n",
                "    download_file(ANNOTATION_URLS[split], zip_path)\n",
                "    \n",
                "    # Extract annotations\n",
                "    if not os.path.exists(f'annotations/instances_{split}2017.json'):\n",
                "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
                "            zip_ref.extractall('.')\n",
                "    \n",
                "    # Remove zip file to save space\n",
                "    if os.path.exists(zip_path):\n",
                "        os.remove(zip_path)\n",
                "        \n",
                "    return f'annotations/instances_{split}2017.json'\n",
                "\n",
                "def get_filtered_image_ids(annotation_file, categories_to_keep, min_area=655, max_per_category=None):\n",
                "    \"\"\"Get list of image IDs that contain the specified categories with a maximum per category\"\"\"\n",
                "    coco = COCO(annotation_file)\n",
                "    image_ids_by_category = {}  # To track image IDs per category\n",
                "    final_image_ids = set()  # To track final selected image IDs\n",
                "    \n",
                "    random.seed(42)\n",
                "    \n",
                "    for cat_id in categories_to_keep:\n",
                "        cat_info = coco.loadCats(cat_id)[0]\n",
                "        print(f\"Finding images with category {cat_id} ({cat_info['name']})\")\n",
                "        \n",
                "        ann_ids = coco.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
                "        anns = coco.loadAnns(ann_ids)\n",
                "        valid_anns = [ann for ann in anns if ann['area'] >= min_area]\n",
                "        img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
                "        \n",
                "        # Shuffle the image IDs to get a random selection\n",
                "        random.shuffle(img_ids)\n",
                "        \n",
                "        # Apply max_per_category limit if specified\n",
                "        if max_per_category is not None and len(img_ids) > max_per_category:\n",
                "            print(f\"Limiting category {cat_id} ({cat_info['name']}) to {max_per_category} images\")\n",
                "            img_ids = img_ids[:max_per_category]\n",
                "            \n",
                "        image_ids_by_category[cat_id] = img_ids\n",
                "        final_image_ids.update(img_ids)\n",
                "    \n",
                "    # Convert to list before returning\n",
                "    final_image_ids = list(final_image_ids)\n",
                "    \n",
                "    # Print statistics\n",
                "    print(\"\\nCategory statistics:\")\n",
                "    for cat_id in categories_to_keep:\n",
                "        cat_info = coco.loadCats(cat_id)[0]\n",
                "        print(f\"- {cat_info['name']}: {len(image_ids_by_category[cat_id])} images\")\n",
                "    print(f\"\\nTotal unique images selected: {len(final_image_ids)}\")\n",
                "    \n",
                "    return final_image_ids, coco\n",
                "\n",
                "def download_specific_images(image_ids, coco, split, output_dir):\n",
                "    \"\"\"Download only the specific images by ID\"\"\"\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "    \n",
                "    # Get base URL for images\n",
                "    base_url = f\"http://images.cocodataset.org/train2017/\" if split == \"train\" else \"http://images.cocodataset.org/val2017/\"\n",
                "    \n",
                "    for img_id in tqdm(image_ids, desc=f\"Downloading {split} images\"):\n",
                "        img_info = coco.loadImgs(img_id)[0]\n",
                "        file_name = img_info[\"file_name\"]\n",
                "        url = base_url + file_name\n",
                "        \n",
                "        # Create subdirectories if needed\n",
                "        os.makedirs(os.path.join(output_dir, os.path.dirname(file_name)), exist_ok=True)\n",
                "        \n",
                "        # Download image\n",
                "        target_path = os.path.join(output_dir, file_name)\n",
                "        if not os.path.exists(target_path):\n",
                "            try:\n",
                "                download_file(url, target_path)\n",
                "            except Exception as e:\n",
                "                print(f\"Error downloading {url}: {e}\")\n",
                "\n",
                "# Process training data\n",
                "print(\"Processing training data...\")\n",
                "train_ann_file = download_and_extract_annotations('train')\n",
                "train_image_ids, train_coco = get_filtered_image_ids(train_ann_file, CATEGORIES_TO_KEEP, max_per_category=MAX_IMAGES_PER_CATEGORY)\n",
                "download_specific_images(train_image_ids, train_coco, 'train', 'data/train')\n",
                "\n",
                "# Process validation data\n",
                "print(\"Processing validation data...\")\n",
                "val_ann_file = download_and_extract_annotations('val')\n",
                "val_image_ids, val_coco = get_filtered_image_ids(val_ann_file, CATEGORIES_TO_KEEP, max_per_category=int(0.3*MAX_IMAGES_PER_CATEGORY))\n",
                "download_specific_images(val_image_ids, val_coco, 'val', 'data/validation')\n",
                "\n",
                "# Save the configuration for future use\n",
                "config = {\n",
                "    \"train_image_dir\": \"data/train\",\n",
                "    \"val_image_dir\": \"data/validation\",\n",
                "    \"train_annotation_file\": \"data/labels/labels_train.json\",\n",
                "    \"val_annotation_file\": \"data/labels/labels_val.json\",\n",
                "    \"categories\": CATEGORIES_TO_KEEP,\n",
                "    \"max_images_per_category\": MAX_IMAGES_PER_CATEGORY\n",
                "}\n",
                "\n",
                "# Create labels directory if it doesn't exist\n",
                "os.makedirs(\"data/labels\", exist_ok=True)\n",
                "\n",
                "# Also save filtered annotations for compatibility with other code\n",
                "def save_filtered_annotations(source_ann_file, image_ids, output_file):\n",
                "    \"\"\"Save a filtered version of annotations containing only the selected images\"\"\"\n",
                "    with open(source_ann_file, 'r') as f:\n",
                "        annotations = json.load(f)\n",
                "    \n",
                "    # Filter images\n",
                "    annotations['images'] = [img for img in annotations['images'] if img['id'] in image_ids]\n",
                "    \n",
                "    # Filter annotations\n",
                "    image_id_set = set(image_ids)\n",
                "    annotations['annotations'] = [ann for ann in annotations['annotations'] \n",
                "                                if ann['image_id'] in image_id_set and \n",
                "                                ann['category_id'] in CATEGORIES_TO_KEEP and\n",
                "                                ann['area'] >= 655]\n",
                "    \n",
                "    with open(output_file, 'w') as f:\n",
                "        json.dump(annotations, f)\n",
                "    \n",
                "    print(f\"Saved filtered annotations to {output_file}\")\n",
                "\n",
                "# Save filtered annotations\n",
                "save_filtered_annotations(train_ann_file, train_image_ids, 'data/labels/labels_train.json')\n",
                "save_filtered_annotations(val_ann_file, val_image_ids, 'data/labels/labels_val.json')\n",
                "\n",
                "with open(\"dataset_download_config.json\", \"w\") as f:\n",
                "    json.dump(config, f)\n",
                "\n",
                "print(\"Configuration saved to dataset_config.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "03e11cb8",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.patches as patches\n",
                "import torch\n",
                "from torch.utils.data import Dataset\n",
                "import torchvision.transforms as transforms\n",
                "from pycocotools.coco import COCO\n",
                "from PIL import Image\n",
                "import os\n",
                "import numpy as np\n",
                "import cv2  # OpenCV needed for polygon drawing\n",
                "from pycocotools import mask as coco_mask\n",
                "from matplotlib import pyplot as plt\n",
                "import shutil\n",
                "\n",
                "config = json.load(open(\"dataset_download_config.json\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "15a7849b",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "class CocoSegmentationDatasetMRCNN(Dataset):\n",
                "    def __init__(self, image_dir, seg_annotation_file, categories_to_keep=[1], min_area_threshold=655, output_dir=None):\n",
                "        self.image_dir = image_dir\n",
                "        self.coco_seg = COCO(seg_annotation_file)\n",
                "        self.min_area_threshold = min_area_threshold\n",
                "        self.categories_to_keep = categories_to_keep\n",
                "        self.output_dir = output_dir\n",
                "        \n",
                "        # Filter images to keep only those containing objects from specified categories\n",
                "        self.image_ids = []\n",
                "        for cat_id in self.categories_to_keep:\n",
                "            ann_ids = self.coco_seg.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
                "            anns = self.coco_seg.loadAnns(ann_ids)\n",
                "            valid_anns = [ann for ann in anns if ann['area'] >= self.min_area_threshold]\n",
                "            img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
                "            self.image_ids.extend(img_ids)\n",
                "        \n",
                "        # Remove duplicates\n",
                "        self.image_ids = list(set(self.image_ids))\n",
                "        print(f\"Dataset contains {len(self.image_ids)} images with categories {categories_to_keep}\")\n",
                "        \n",
                "        # For visualization, create a category mapping\n",
                "        self.category_map = {}\n",
                "        for cat_id in self.categories_to_keep:\n",
                "            cat_info = self.coco_seg.loadCats(cat_id)[0]\n",
                "            self.category_map[cat_id] = cat_info['name']\n",
                "        \n",
                "        # Copy images to output directory if specified\n",
                "        if output_dir:\n",
                "            self.copy_images_to_output_dir()\n",
                "\n",
                "    def copy_images_to_output_dir(self):\n",
                "        \"\"\"Copy filtered images to the output directory\"\"\"\n",
                "        if not self.output_dir:\n",
                "            return\n",
                "            \n",
                "        # Create output directory\n",
                "        os.makedirs(self.output_dir, exist_ok=True)\n",
                "        \n",
                "        print(f\"Copying {len(self.image_ids)} images to {self.output_dir}...\")\n",
                "        copied_count = 0\n",
                "        \n",
                "        for img_id in self.image_ids:\n",
                "            # Get image info\n",
                "            img_info = self.coco_seg.loadImgs(img_id)[0]\n",
                "            \n",
                "            # Source and destination paths\n",
                "            src_path = os.path.join(self.image_dir, img_info[\"file_name\"])\n",
                "            dst_path = os.path.join(self.output_dir, img_info[\"file_name\"])\n",
                "            \n",
                "            # Copy image if source exists\n",
                "            if os.path.exists(src_path):\n",
                "                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
                "                shutil.copy(src_path, dst_path)\n",
                "                copied_count += 1\n",
                "            else:\n",
                "                print(f\"Warning: Could not find {src_path}\")\n",
                "        \n",
                "        print(f\"Copied {copied_count} images to {self.output_dir}\")\n",
                "    \n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_ids)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        image_id = self.image_ids[idx]\n",
                "        \n",
                "        # Load image\n",
                "        image_info = self.coco_seg.loadImgs(image_id)[0]\n",
                "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
                "        image = Image.open(image_path).convert(\"RGB\")\n",
                "        \n",
                "        # Convert to tensor\n",
                "        image = transforms.ToTensor()(image)\n",
                "        \n",
                "        # Load annotations\n",
                "        ann_ids = self.coco_seg.getAnnIds(imgIds=image_id, catIds=self.categories_to_keep, iscrowd=False)\n",
                "        anns = self.coco_seg.loadAnns(ann_ids)\n",
                "        \n",
                "        # Initialize target dictionary\n",
                "        target = {}\n",
                "        boxes = []\n",
                "        masks = []\n",
                "        labels = []\n",
                "        category_ids = []  # Keep original category IDs for reference\n",
                "        \n",
                "        # Process each annotation\n",
                "        for ann in anns:\n",
                "            if ann['area'] < self.min_area_threshold:\n",
                "                continue\n",
                "                \n",
                "            # Get bounding box\n",
                "            bbox = ann['bbox']  # [x, y, width, height] format\n",
                "            # Convert to [x1, y1, x2, y2] format\n",
                "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
                "            \n",
                "            # Get mask\n",
                "            mask = self.coco_seg.annToMask(ann)\n",
                "            masks.append(torch.as_tensor(mask, dtype=torch.uint8))\n",
                "            \n",
                "            # Keep original category ID for reference\n",
                "            category_ids.append(ann['category_id'])\n",
                "            \n",
                "            # For segmentation only, use class 1 for all foreground objects\n",
                "            labels.append(1)  # 1 for foreground, 0 for background\n",
                "        \n",
                "        # Convert to tensor format\n",
                "        if boxes:\n",
                "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.stack(masks)\n",
                "            target[\"category_ids\"] = torch.as_tensor(category_ids, dtype=torch.int64)  # original IDs for reference\n",
                "        else:\n",
                "            # Empty annotations\n",
                "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.zeros((0, image.shape[1], image.shape[2]), dtype=torch.uint8)\n",
                "            target[\"category_ids\"] = torch.zeros((0), dtype=torch.int64)\n",
                "        \n",
                "        target[\"image_id\"] = torch.tensor([image_id])\n",
                "        \n",
                "        return image, target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6e23ae95",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "dataset_train = CocoSegmentationDatasetMRCNN(\n",
                "    config[\"train_image_dir\"],\n",
                "    config[\"train_annotation_file\"],\n",
                "    categories_to_keep=[84,31,52],\n",
                "    min_area_threshold=655,\n",
                "    output_dir=None  # No need to copy since we already downloaded only what we need\n",
                ")\n",
                "\n",
                "dataset_val = CocoSegmentationDatasetMRCNN(\n",
                "    config[\"val_image_dir\"],\n",
                "    config[\"val_annotation_file\"],\n",
                "    categories_to_keep=[84,31,52],\n",
                "    min_area_threshold=655,\n",
                "    output_dir=None  # No need to copy since we already downloaded only what we need\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ovis",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
