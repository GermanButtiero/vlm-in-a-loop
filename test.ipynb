{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "4602a148",
                "language": "markdown"
            },
            "source": [
                "In order to download only a subset of the COCO dataset we need to:\n",
                "\n",
                "1- Download and extract the annotation files\n",
                "\n",
                "2- Filter the annotations to identify images containing our target categories\n",
                "\n",
                "3- Download only a limited number of images per category to the \"data\" folder\n",
                "\n",
                "4- Move the data folder to your HPC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "11d2d2de",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing training data...\n",
                        "Downloading http://images.cocodataset.org/annotations/annotations_trainval2017.zip to annotations_train2017.zip\n"
                    ]
                },
                {
                    "ename": "HTTPError",
                    "evalue": "503 Server Error: Service Unavailable for url: http://images.cocodataset.org/annotations/annotations_trainval2017.zip",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 129\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Process training data\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m train_ann_file \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_extract_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m train_image_ids, train_coco \u001b[38;5;241m=\u001b[39m get_filtered_image_ids(train_ann_file, CATEGORIES_TO_KEEP, max_per_category\u001b[38;5;241m=\u001b[39mMAX_IMAGES_PER_CATEGORY)\n\u001b[1;32m    131\u001b[0m download_specific_images(train_image_ids, train_coco, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mdownload_and_extract_annotations\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Download annotations\u001b[39;00m\n\u001b[1;32m     50\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m2017.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mANNOTATION_URLS\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Extract annotations\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations/instances_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m2017.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
                        "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, target_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(target_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m):\n",
                        "File \u001b[0;32m~/anaconda3/envs/vlm/lib/python3.9/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
                        "\u001b[0;31mHTTPError\u001b[0m: 503 Server Error: Service Unavailable for url: http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "import requests\n",
                "import fiftyone as fo\n",
                "from pycocotools.coco import COCO\n",
                "from tqdm import tqdm\n",
                "\n",
                "# URLs for COCO annotation files\n",
                "ANNOTATION_URLS = {\n",
                "    'train': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
                "    'val': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
                "    'test': 'http://images.cocodataset.org/annotations/image_info_test2017.zip'\n",
                "}\n",
                "\n",
                "# URLs for image files\n",
                "IMAGE_URLS = {\n",
                "    'train': 'http://images.cocodataset.org/zips/train2017.zip',\n",
                "    'val': 'http://images.cocodataset.org/zips/val2017.zip',\n",
                "    'test': 'http://images.cocodataset.org/zips/test2017.zip'\n",
                "}\n",
                "\n",
                "# Categories we want to download (category IDs 84, 31, 52)\n",
                "CATEGORIES_TO_KEEP = [84, 31, 52]\n",
                "\n",
                "# Maximum images per category (set to None for unlimited)\n",
                "MAX_IMAGES_PER_CATEGORY = 100  # Change this number as needed\n",
                "\n",
                "def download_file(url, target_path):\n",
                "    \"\"\"Download a file if it doesn't exist\"\"\"\n",
                "    if os.path.exists(target_path):\n",
                "        print(f\"File already exists: {target_path}\")\n",
                "        return\n",
                "    \n",
                "    print(f\"Downloading {url} to {target_path}\")\n",
                "    with requests.get(url, stream=True) as r:\n",
                "        r.raise_for_status()\n",
                "        with open(target_path, 'wb') as f:\n",
                "            for chunk in r.iter_content(chunk_size=8192):\n",
                "                f.write(chunk)\n",
                "\n",
                "def download_and_extract_annotations(split):\n",
                "    \"\"\"Download and extract annotation files for a specific split\"\"\"\n",
                "    import zipfile\n",
                "    \n",
                "    # Create directories\n",
                "    os.makedirs('annotations', exist_ok=True)\n",
                "    \n",
                "    # Download annotations\n",
                "    zip_path = f'annotations_{split}2017.zip'\n",
                "    download_file(ANNOTATION_URLS[split], zip_path)\n",
                "    \n",
                "    # Extract annotations\n",
                "    if not os.path.exists(f'annotations/instances_{split}2017.json'):\n",
                "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
                "            zip_ref.extractall('.')\n",
                "    \n",
                "    # Remove zip file to save space\n",
                "    if os.path.exists(zip_path):\n",
                "        os.remove(zip_path)\n",
                "        \n",
                "    return f'annotations/instances_{split}2017.json'\n",
                "\n",
                "def get_filtered_image_ids(annotation_file, categories_to_keep, min_area=655, max_per_category=None):\n",
                "    \"\"\"Get list of image IDs that contain the specified categories with a maximum per category\"\"\"\n",
                "    coco = COCO(annotation_file)\n",
                "    image_ids_by_category = {}  # To track image IDs per category\n",
                "    final_image_ids = set()  # To track final selected image IDs\n",
                "    \n",
                "    random.seed(42)\n",
                "    \n",
                "    for cat_id in categories_to_keep:\n",
                "        cat_info = coco.loadCats(cat_id)[0]\n",
                "        print(f\"Finding images with category {cat_id} ({cat_info['name']})\")\n",
                "        \n",
                "        ann_ids = coco.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
                "        anns = coco.loadAnns(ann_ids)\n",
                "        valid_anns = [ann for ann in anns if ann['area'] >= min_area]\n",
                "        img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
                "        \n",
                "        # Shuffle the image IDs to get a random selection\n",
                "        random.shuffle(img_ids)\n",
                "        \n",
                "        # Apply max_per_category limit if specified\n",
                "        if max_per_category is not None and len(img_ids) > max_per_category:\n",
                "            print(f\"Limiting category {cat_id} ({cat_info['name']}) to {max_per_category} images\")\n",
                "            img_ids = img_ids[:max_per_category]\n",
                "            \n",
                "        image_ids_by_category[cat_id] = img_ids\n",
                "        final_image_ids.update(img_ids)\n",
                "    \n",
                "    # Convert to list before returning\n",
                "    final_image_ids = list(final_image_ids)\n",
                "    \n",
                "    # Print statistics\n",
                "    print(\"\\nCategory statistics:\")\n",
                "    for cat_id in categories_to_keep:\n",
                "        cat_info = coco.loadCats(cat_id)[0]\n",
                "        print(f\"- {cat_info['name']}: {len(image_ids_by_category[cat_id])} images\")\n",
                "    print(f\"\\nTotal unique images selected: {len(final_image_ids)}\")\n",
                "    \n",
                "    return final_image_ids, coco\n",
                "\n",
                "def download_specific_images(image_ids, coco, split, output_dir):\n",
                "    \"\"\"Download only the specific images by ID\"\"\"\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "    \n",
                "    # Get base URL for images\n",
                "    base_url = f\"http://images.cocodataset.org/train2017/\" if split == \"train\" else \"http://images.cocodataset.org/val2017/\"\n",
                "    \n",
                "    for img_id in tqdm(image_ids, desc=f\"Downloading {split} images\"):\n",
                "        img_info = coco.loadImgs(img_id)[0]\n",
                "        file_name = img_info[\"file_name\"]\n",
                "        url = base_url + file_name\n",
                "        \n",
                "        # Create subdirectories if needed\n",
                "        os.makedirs(os.path.join(output_dir, os.path.dirname(file_name)), exist_ok=True)\n",
                "        \n",
                "        # Download image\n",
                "        target_path = os.path.join(output_dir, file_name)\n",
                "        if not os.path.exists(target_path):\n",
                "            try:\n",
                "                download_file(url, target_path)\n",
                "            except Exception as e:\n",
                "                print(f\"Error downloading {url}: {e}\")\n",
                "\n",
                "# Process training data\n",
                "print(\"Processing training data...\")\n",
                "train_ann_file = download_and_extract_annotations('train')\n",
                "train_image_ids, train_coco = get_filtered_image_ids(train_ann_file, CATEGORIES_TO_KEEP, max_per_category=MAX_IMAGES_PER_CATEGORY)\n",
                "download_specific_images(train_image_ids, train_coco, 'train', 'data/train')\n",
                "\n",
                "# Process validation data\n",
                "print(\"Processing validation data...\")\n",
                "val_ann_file = download_and_extract_annotations('val')\n",
                "val_image_ids, val_coco = get_filtered_image_ids(val_ann_file, CATEGORIES_TO_KEEP, max_per_category=int(0.3*MAX_IMAGES_PER_CATEGORY))\n",
                "download_specific_images(val_image_ids, val_coco, 'val', 'data/validation')\n",
                "\n",
                "# Save the configuration for future use\n",
                "config = {\n",
                "    \"train_image_dir\": \"data/train\",\n",
                "    \"val_image_dir\": \"data/validation\",\n",
                "    \"train_annotation_file\": \"data/labels/labels_train.json\",\n",
                "    \"val_annotation_file\": \"data/labels/labels_val.json\",\n",
                "    \"categories\": CATEGORIES_TO_KEEP,\n",
                "    \"max_images_per_category\": MAX_IMAGES_PER_CATEGORY\n",
                "}\n",
                "\n",
                "# Create labels directory if it doesn't exist\n",
                "os.makedirs(\"data/labels\", exist_ok=True)\n",
                "\n",
                "# Also save filtered annotations for compatibility with other code\n",
                "def save_filtered_annotations(source_ann_file, image_ids, output_file):\n",
                "    \"\"\"Save a filtered version of annotations containing only the selected images\"\"\"\n",
                "    with open(source_ann_file, 'r') as f:\n",
                "        annotations = json.load(f)\n",
                "    \n",
                "    # Filter images\n",
                "    annotations['images'] = [img for img in annotations['images'] if img['id'] in image_ids]\n",
                "    \n",
                "    # Filter annotations\n",
                "    image_id_set = set(image_ids)\n",
                "    annotations['annotations'] = [ann for ann in annotations['annotations'] \n",
                "                                if ann['image_id'] in image_id_set and \n",
                "                                ann['category_id'] in CATEGORIES_TO_KEEP and\n",
                "                                ann['area'] >= 655]\n",
                "    \n",
                "    with open(output_file, 'w') as f:\n",
                "        json.dump(annotations, f)\n",
                "    \n",
                "    print(f\"Saved filtered annotations to {output_file}\")\n",
                "\n",
                "# Save filtered annotations\n",
                "save_filtered_annotations(train_ann_file, train_image_ids, 'data/labels/labels_train.json')\n",
                "save_filtered_annotations(val_ann_file, val_image_ids, 'data/labels/labels_val.json')\n",
                "\n",
                "with open(\"dataset_download_config.json\", \"w\") as f:\n",
                "    json.dump(config, f)\n",
                "\n",
                "print(\"Configuration saved to dataset_config.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "03e11cb8",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/arth/anaconda3/envs/vlm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.patches as patches\n",
                "import torch\n",
                "from torch.utils.data import Dataset\n",
                "import torchvision.transforms as transforms\n",
                "from pycocotools.coco import COCO\n",
                "from PIL import Image\n",
                "import os\n",
                "import numpy as np\n",
                "import cv2  # OpenCV needed for polygon drawing\n",
                "from pycocotools import mask as coco_mask\n",
                "from matplotlib import pyplot as plt\n",
                "import shutil\n",
                "\n",
                "config = json.load(open(\"dataset_download_config.json\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "15a7849b",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "class CocoSegmentationDatasetMRCNN(Dataset):\n",
                "    def __init__(self, image_dir, seg_annotation_file, categories_to_keep=[1], min_area_threshold=655, output_dir=None):\n",
                "        self.image_dir = image_dir\n",
                "        self.coco_seg = COCO(seg_annotation_file)\n",
                "        self.min_area_threshold = min_area_threshold\n",
                "        self.categories_to_keep = categories_to_keep\n",
                "        self.output_dir = output_dir\n",
                "        \n",
                "        # Filter images to keep only those containing objects from specified categories\n",
                "        self.image_ids = []\n",
                "        for cat_id in self.categories_to_keep:\n",
                "            ann_ids = self.coco_seg.getAnnIds(catIds=[cat_id], iscrowd=False)\n",
                "            anns = self.coco_seg.loadAnns(ann_ids)\n",
                "            valid_anns = [ann for ann in anns if ann['area'] >= self.min_area_threshold]\n",
                "            img_ids = list(set([ann['image_id'] for ann in valid_anns]))\n",
                "            self.image_ids.extend(img_ids)\n",
                "        \n",
                "        # Remove duplicates\n",
                "        self.image_ids = list(set(self.image_ids))\n",
                "        print(f\"Dataset contains {len(self.image_ids)} images with categories {categories_to_keep}\")\n",
                "        \n",
                "        # For visualization, create a category mapping\n",
                "        self.category_map = {}\n",
                "        for cat_id in self.categories_to_keep:\n",
                "            cat_info = self.coco_seg.loadCats(cat_id)[0]\n",
                "            self.category_map[cat_id] = cat_info['name']\n",
                "        \n",
                "        # Copy images to output directory if specified\n",
                "        if output_dir:\n",
                "            self.copy_images_to_output_dir()\n",
                "\n",
                "    def copy_images_to_output_dir(self):\n",
                "        \"\"\"Copy filtered images to the output directory\"\"\"\n",
                "        if not self.output_dir:\n",
                "            return\n",
                "            \n",
                "        # Create output directory\n",
                "        os.makedirs(self.output_dir, exist_ok=True)\n",
                "        \n",
                "        print(f\"Copying {len(self.image_ids)} images to {self.output_dir}...\")\n",
                "        copied_count = 0\n",
                "        \n",
                "        for img_id in self.image_ids:\n",
                "            # Get image info\n",
                "            img_info = self.coco_seg.loadImgs(img_id)[0]\n",
                "            \n",
                "            # Source and destination paths\n",
                "            src_path = os.path.join(self.image_dir, img_info[\"file_name\"])\n",
                "            dst_path = os.path.join(self.output_dir, img_info[\"file_name\"])\n",
                "            \n",
                "            # Copy image if source exists\n",
                "            if os.path.exists(src_path):\n",
                "                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
                "                shutil.copy(src_path, dst_path)\n",
                "                copied_count += 1\n",
                "            else:\n",
                "                print(f\"Warning: Could not find {src_path}\")\n",
                "        \n",
                "        print(f\"Copied {copied_count} images to {self.output_dir}\")\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_ids)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        image_id = self.image_ids[idx]\n",
                "        \n",
                "        # Load image\n",
                "        image_info = self.coco_seg.loadImgs(image_id)[0]\n",
                "        image_path = os.path.join(self.image_dir, image_info[\"file_name\"])\n",
                "        image = Image.open(image_path).convert(\"RGB\")\n",
                "        \n",
                "        # Convert to tensor\n",
                "        image = transforms.ToTensor()(image)\n",
                "        \n",
                "        # Load annotations\n",
                "        ann_ids = self.coco_seg.getAnnIds(imgIds=image_id, catIds=self.categories_to_keep, iscrowd=False)\n",
                "        anns = self.coco_seg.loadAnns(ann_ids)\n",
                "        \n",
                "        # Initialize target dictionary\n",
                "        target = {}\n",
                "        boxes = []\n",
                "        masks = []\n",
                "        labels = []\n",
                "        category_ids = []  # Keep original category IDs for reference\n",
                "        \n",
                "        # Process each annotation\n",
                "        for ann in anns:\n",
                "            if ann['area'] < self.min_area_threshold:\n",
                "                continue\n",
                "                \n",
                "            # Get bounding box\n",
                "            bbox = ann['bbox']  # [x, y, width, height] format\n",
                "            # Convert to [x1, y1, x2, y2] format\n",
                "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
                "            \n",
                "            # Get mask\n",
                "            mask = self.coco_seg.annToMask(ann)\n",
                "            masks.append(torch.as_tensor(mask, dtype=torch.uint8))\n",
                "            \n",
                "            # Keep original category ID for reference\n",
                "            category_ids.append(ann['category_id'])\n",
                "            \n",
                "            # For segmentation only, use class 1 for all foreground objects\n",
                "            labels.append(1)  # 1 for foreground, 0 for background\n",
                "        \n",
                "        # Convert to tensor format\n",
                "        if boxes:\n",
                "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.stack(masks)\n",
                "            target[\"category_ids\"] = torch.as_tensor(category_ids, dtype=torch.int64)  # original IDs for reference\n",
                "        else:\n",
                "            # Empty annotations\n",
                "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.zeros((0, image.shape[1], image.shape[2]), dtype=torch.uint8)\n",
                "            target[\"category_ids\"] = torch.zeros((0), dtype=torch.int64)\n",
                "        \n",
                "        target[\"image_id\"] = torch.tensor([image_id])\n",
                "        \n",
                "        return image, target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6e23ae95",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading annotations into memory...\n",
                        "Done (t=0.01s)\n",
                        "creating index...\n",
                        "index created!\n",
                        "Dataset contains 300 images with categories [84, 31, 52]\n",
                        "loading annotations into memory...\n",
                        "Done (t=0.01s)\n",
                        "creating index...\n",
                        "index created!\n",
                        "Dataset contains 283 images with categories [84, 31, 52]\n"
                    ]
                }
            ],
            "source": [
                "dataset_train = CocoSegmentationDatasetMRCNN(\n",
                "    config[\"train_image_dir\"],\n",
                "    config[\"train_annotation_file\"],\n",
                "    categories_to_keep=[84,31,52],\n",
                "    min_area_threshold=655,\n",
                "    output_dir=None  # No need to copy since we already downloaded only what we need\n",
                ")\n",
                "\n",
                "dataset_val = CocoSegmentationDatasetMRCNN(\n",
                "    config[\"val_image_dir\"],\n",
                "    config[\"val_annotation_file\"],\n",
                "    categories_to_keep=[84,31,52],\n",
                "    min_area_threshold=655,\n",
                "    output_dir=None  # No need to copy since we already downloaded only what we need\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "vlm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
